# Confusion matrices with memory and prediction

This repository contains the code I wrote to analyze and create figures used in the *Confusion matrices with memory and prediction in an organoid* section of the manuscript titled **Analyzing an organismâ€™s sensors using Maximum Entropy models with bias, variance, and confusion matrices**, currently in preparation. [This paper](https://academic.oup.com/pnasnexus/article/2/6/pgad188/7202378) provides more context for what each file in this repo does.

## Folders

- **figs**: All figures that are used in the aforementioned section are stored here.

- **global**: This folder stores the `.npy` files generated by **analysis.py** which contains the performance metrics (predictive accuracy, true positive/negative rate) for model and baseline with respect to timeshift and subsystem size for *global/optogenetic* stimulation.

- **local**: This folder stores the `.npy` files generated by **analysis.py** which contains the performance metrics (predictive accuracy, true positive/negative rate) for model and baseline with respect to timeshift and subsystem size for *focal/electrical* stimulation.

## Files

- **gen cm metrics.py**: This file runs the Maximum Entropy main analysis and generates performance metrics for the confusion matrices. You will be prompted to enter the type of stimulation for the files you're analyzing (`local` or `global`). It then opens the [data](https://datadryad.org/dataset/doi:10.5061/dryad.p5hqbzkqj) we are using, performs necessary array manipulations to reflect timeshift, determines optimal neuron subsystems via correlation matrices, and runs the MaxEnt model on the data to generate a *J* matrix. Finally, it develops an estimator which is then characterized for accuracy, and final benchmarks are saved as `.npy` files in the **global** and **local** folders.

- **cm metrics plot.py**: Using the `.npy` files generated by the analysis file, this file plots the predictive accuracy and true positive/negative rates of both baseline and model to illustrate any noticeable improvements using the MaxEnt model. Figures are stored in the **figs** folder as *cm metrics.png*.

- **hourly.py**: Splits data up into hourly segments, then runs MaxEnt analysis on each hour for both optogenetic and electric stimulation. Uses subsystem size of six neurons at 0ms timeshift. Generates figure in **figs** folder.

- **statistical_tests.py**: Runs Shapiro-Wilk normality test and t-test and on experimental data.

- **binsizes.py**: Investigates the effect of time resolution on confusion matrix metrics. Assumes subsystem size of six neurons at best performance timeshift (ie. 0 ms for electric and -100 ms for optogenetic stimulation).

- **physf.py**: Contains all the physics-related functions I used.

- **dataf.py**: Contains all the data manipulation/analysis related functions I used.

## Dependencies

To run this, I used the following libraries and versions:
```
Python          3.11.13
h5py            3.15.1
matplotlib      3.10.6
numpy           2.3.3
pandas          2.3.2
scipy           1.16.2
seaborn         0.13.2

time
re
```